{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## WHO GHO Indicators for Obesity Research\n",
    "\n",
    "**Analysis of 3,039 available WHO indicators found 819 obesity-related indicators:**\n",
    "\n",
    "| Category | Count | Key Examples |\n",
    "|----------|-------|--------------|\n",
    "| **Obesity Measures** | 29 | `NCD_BMI_30A` (adult obesity), `NCD_BMI_25A` (overweight), child malnutrition |\n",
    "| **Physical Activity** | 18 | `NCD_PAC` (insufficient activity), PA guidelines, workplace initiatives |\n",
    "| **Nutrition/Diet** | 76 | Minimum acceptable diet, food safety, unhealthy diet policies |\n",
    "| **Diabetes/Glucose** | 22 | `NCD_GLUC_04` (raised blood glucose), diabetes testing, HbA1c |\n",
    "| **Cardiovascular** | 27 | `BP_04` (hypertension), blood pressure, heart disease mortality |\n",
    "| **Tobacco** | 249 | Tobacco use, advertising bans, tobacco control programs |\n",
    "| **Alcohol** | 275 | Alcohol consumption, use disorders, BAC limits |\n",
    "| **Socioeconomic** | 84 | Poverty (`CCO_1`), literacy, income inequality |\n",
    "| **Geographic** | 13 | Urban/rural population, city coverage |\n",
    "| **Healthcare** | 21 | Health expenditure, immunization coverage, financial protection |\n",
    "| **Other** | 5 | Miscellaneous health indicators |\n",
    "\n",
    "    \"**Full list saved to:** `data/metadata/who_indicators_obesity_related.csv`\\n\",\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Google Colab\n",
    "# Clone repository to Google Drive and point working directory to /code directory\n",
    "# Uncomment and edit the lines below if running in Colab:\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/Obesity/code')  # Change this to your path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Obesity â€” Data Collection\n",
    "\n",
    "Download WHO Global Health Observatory indicator data, merge into a single CSV file.\n",
    "\n",
    "**Quick Start:** Change `query` below to select indicators, then run all cells.\n",
    "\n",
    "**Workflow:**\n",
    "1. Define core indicators for filtering\n",
    "2. Download indicators matching query\n",
    "3. Save full dataset to `who_obesity_data.csv`\n",
    "4. Filter to core indicators and save to `who_obesity_core_data.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "# Set default visualization style\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('deep')\n",
    "\n",
    "# Query to search for obesity-related indicators\n",
    "# Using descriptive keywords that appear in indicator  or codes\n",
    "query = ('BMI|obesity|overweight|'\n",
    "         'physical activity|'\n",
    "         'diabetes|glucose|blood sugar|'\n",
    "         'blood pressure|hypertension|'\n",
    "         'cholesterol|'\n",
    "         'tobacco|smoking|'\n",
    "         'alcohol|'\n",
    "         'salt|sodium|'\n",
    "         'population|'\n",
    "         'life expectancy|'\n",
    "         'immunization|'\n",
    "         'poverty|'\n",
    "         'inequality|'\n",
    "         'national income|gross national income|GNI')\n",
    "\n",
    "print(f'Query: {query}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Load all available indicators\n",
    "indicators_df = pd.read_csv('../data/metadata/who_indicators_all.csv')[['IndicatorCode', 'IndicatorName']].drop_duplicates()\n",
    "\n",
    "# Load existing data\n",
    "data_file = '../data/who_obesity_data.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "print(f' Loaded existing data: {len(df):,} rows')\n",
    "\n",
    "existing_codes = set(df['IndicatorCode'].unique())\n",
    "print(f'  Existing: {len(existing_codes)} indicators')\n",
    "\n",
    "# Filter by query\n",
    "query_mask = (indicators_df['IndicatorName'].str.contains(query, case=False, na=False) | \n",
    "              indicators_df['IndicatorCode'].str.contains(query, case=False, na=False))\n",
    "\n",
    "# Exclude existing indicators\n",
    "new_df = indicators_df[query_mask][~indicators_df['IndicatorCode'].isin(existing_codes)]\n",
    "\n",
    "selected_indicators = new_df.to_dict('records')\n",
    "\n",
    "print(f'\\nNew Indicators to Download: {len(selected_indicators)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Download Indicator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download indicator data\n",
    "if len(selected_indicators) > 0:\n",
    "    new_rows = []  # Collect new rows\n",
    "\n",
    "    for idx, indicator in enumerate(selected_indicators, 1):\n",
    "        code = indicator.get(\"IndicatorCode\")\n",
    "        name = indicator.get(\"IndicatorName\", \"\")\n",
    "        print(f\"[{idx}/{len(selected_indicators)}] {code}...\", end=\" \")\n",
    "    \n",
    "        try:\n",
    "            r = requests.get(f\"https://ghoapi.azureedge.net/api/{code}\", timeout=30)\n",
    "            if r.status_code == 200:\n",
    "                records = r.json().get(\"value\", [])\n",
    "            \n",
    "                if len(records) == 0:\n",
    "                    # Add dummy row with indicator info, other columns will be NA\n",
    "                    dummy_row = {\"IndicatorCode\": code, \"IndicatorName\": name}\n",
    "                    new_rows.append(dummy_row)\n",
    "                    print(\"no data\")\n",
    "                else:\n",
    "                    for rec in records:\n",
    "                        rec[\"IndicatorCode\"] = code\n",
    "                        rec[\"IndicatorName\"] = name\n",
    "                    new_rows.extend(records)\n",
    "                    print(f\"{len(records)} records\")\n",
    "            else:\n",
    "                print(f\"Error {r.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        time.sleep(0.2)\n",
    "    \n",
    "    # Append new rows to df\n",
    "    if len(new_rows) > 0:\n",
    "        downloaded_df = pd.DataFrame(new_rows)\n",
    "        df = pd.concat([df, downloaded_df], ignore_index=True)\n",
    "        print(f\"\\nAdded {len(new_rows):,} rows, {downloaded_df['IndicatorCode'].nunique()} indicators\")\n",
    "else:\n",
    "    print(\"No new indicators to download\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data - only when new indicators were downloaded\n",
    "if len(selected_indicators) > 0:\n",
    "    import os\n",
    "    \n",
    "    # Save to full dataset file (includes all existing + newly downloaded data)\n",
    "    output_file = \"../data/who_obesity_data.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    file_size_mb = os.path.getsize(output_file) / 1024 / 1024\n",
    "    \n",
    "    print(f\"Saved: {len(df):,} rows, {df['IndicatorCode'].nunique()} indicators, {file_size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"No new data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Save Core Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Core Dataset\n",
    "\n",
    "# Load core indicators from CSV\n",
    "core_indicators_df = pd.read_csv('../data/metadata/who_indicators_obesity_core.csv')\n",
    "all_core_codes = core_indicators_df['IndicatorCode'].tolist()\n",
    "\n",
    "# Filter full dataset to only core indicators\n",
    "core_df = df[df['IndicatorCode'].isin(all_core_codes)].copy()\n",
    "\n",
    "# Save core data\n",
    "core_output_file = \"../data/who_obesity_core_data.csv\"\n",
    "core_df.to_csv(core_output_file, index=False)\n",
    "\n",
    "print(f\"Saved core dataset: {len(core_df):,} rows, {core_df['IndicatorCode'].nunique()} indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## View Results - All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Dataset Overview Dashboard\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('=' * 80)\n",
    "print('FULL DATASET OVERVIEW'.center(80))\n",
    "print('=' * 80)\n",
    "\n",
    "# Basic statistics\n",
    "total_rows = len(df)\n",
    "total_indicators = df['IndicatorCode'].nunique()\n",
    "total_countries = df['SpatialDim'].nunique()\n",
    "year_range = f\"{df['TimeDim'].min():.0f} - {df['TimeDim'].max():.0f}\"\n",
    "\n",
    "print(f'\\nData Summary:')\n",
    "print(f'  Records: {total_rows:,}')\n",
    "print(f'  Indicators: {total_indicators}')\n",
    "print(f'  Countries/Regions: {total_countries}')\n",
    "print(f'  Years: {year_range}')\n",
    "\n",
    "# Data coverage\n",
    "year_counts = df['TimeDim'].value_counts().sort_index()\n",
    "print('\\nTop 5 Years with Most Data:')\n",
    "for year, count in year_counts.nlargest(5).items():\n",
    "    print(f'  {year:.0f}: {count:,} records')\n",
    "\n",
    "print('\\n' + '=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Add Indicator Categories to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load categorized indicators and join to main dataframe\n",
    "indicators_cat = pd.read_csv('../data/metadata/who_indicators_obesity_related.csv')[['IndicatorCode', 'Category']]\n",
    "\n",
    "# Join categories to df\n",
    "df = df.join(indicators_cat.set_index('IndicatorCode'), on='IndicatorCode', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## View Results - Core Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display core dataset\n",
    "core_df = pd.read_csv('../data/who_obesity_core_data.csv')\n",
    "\n",
    "# Load and join categories\n",
    "indicators_cat = pd.read_csv('../data/metadata/who_indicators_obesity_related.csv')[['IndicatorCode', 'Category']]\n",
    "core_df = core_df.join(indicators_cat.set_index('IndicatorCode'), on='IndicatorCode', how='left')\n",
    "\n",
    "print('=' * 80)\n",
    "print('CORE DATASET OVERVIEW'.center(80))\n",
    "print('=' * 80)\n",
    "\n",
    "# Basic statistics\n",
    "print(f'\\nData Summary:')\n",
    "print(f'  Records: {len(core_df):,}')\n",
    "print(f'  Indicators: {core_df[\"IndicatorCode\"].nunique()}')\n",
    "print(f'  Countries/Regions: {core_df[\"SpatialDim\"].nunique()}')\n",
    "print(f'  Years: {core_df[\"TimeDim\"].min():.0f} - {core_df[\"TimeDim\"].max():.0f}')\n",
    "\n",
    "# Top years with data\n",
    "year_counts = core_df['TimeDim'].value_counts().sort_index()\n",
    "print('\\nTop 5 Years with Most Data:')\n",
    "for year, count in year_counts.nlargest(5).items():\n",
    "    print(f'  {year:.0f}: {count:,} records')\n",
    "\n",
    "# Recent data coverage\n",
    "recent_years = core_df[core_df['TimeDim'] >= 2020]['TimeDim'].value_counts().sort_index()\n",
    "print(f'\\nRecent Data (2020+):')\n",
    "print(f'  Records: {recent_years.sum():,} across {len(recent_years)} years')\n",
    "\n",
    "print('\\n' + '=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Merging datasets from different indicators and ploting HeatMap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indicators_codes = core_df['IndicatorCode'].unique()\n",
    "\n",
    "target_indicator = 'NCD_BMI_30A'\n",
    "indicator_code_df_name_list = []\n",
    "core_df = core_df[~core_df[\"Dim1\"].isin([\"SEX_MLE\", \"SEX_FMLE\", \"ALCOHOLTYPE_SA_SPIRITS\", \"ALCOHOLTYPE_SA_BEER\", \"ALCOHOLTYPE_SA_WINE\", \"ALCOHOLTYPE_SA_OTHER_ALCOHOL\"])]\n",
    "core_df_without_dim1 = core_df.drop(columns=\"Dim1\")\n",
    "core_df_without_dim1 = core_df_without_dim1.drop_duplicates()\n",
    "\n",
    "for code in unique_indicators_codes:\n",
    "    if target_indicator != code:\n",
    "        indicators_data_df = core_df_without_dim1[core_df_without_dim1['IndicatorCode'] == code]\n",
    "        indicators_data_df = indicators_data_df[['SpatialDim', 'TimeDim', 'IndicatorCode', 'IndicatorName', 'NumericValue', 'Value']]\n",
    "        indicator_code_df_name_list.append(indicators_data_df)\n",
    "    else:\n",
    "        target_indicator_data_df = core_df_without_dim1[core_df_without_dim1['IndicatorCode'] == code] \n",
    "        target_indicator_data_df = target_indicator_data_df[['SpatialDim', 'TimeDim', 'IndicatorCode', 'IndicatorName', 'NumericValue', 'Value']]\n",
    "\n",
    "\n",
    "rename_map = {\n",
    "        \"SpatialDim\": \"CountryCode\",\n",
    "        \"TimeDim\": \"Year\"\n",
    "    }\n",
    "\n",
    "# Rename columns\n",
    "target_indicator_data_df.rename(columns={k: v for k, v in rename_map.items() if k in target_indicator_data_df.columns}, inplace=True)\n",
    "target_indicator_data_df.dropna(subset=[\"CountryCode\", \"Year\", \"NumericValue\"], inplace=True)\n",
    "target_indicator_data_df.to_csv(\"../data/target_indicator_data_df.csv\")\n",
    "\n",
    "merged_indicators_data_df = target_indicator_data_df.copy()\n",
    "merged_indicators_data_df[\"Year\"]  = pd.to_numeric(merged_indicators_data_df[\"Year\"], errors=\"coerce\")\n",
    "merged_indicators_data_df[\"NumericValue\"] = pd.to_numeric(merged_indicators_data_df[\"NumericValue\"], errors=\"coerce\")\n",
    "\n",
    "new_name = merged_indicators_data_df[\"IndicatorCode\"].iloc[0]  # get value from the row\n",
    "merged_indicators_data_df.rename(columns={\"NumericValue\": new_name}, inplace=True)\n",
    "merged_indicators_data_df.drop(columns=\"IndicatorCode\", inplace=True)\n",
    "merged_indicators_data_df.drop(columns=\"IndicatorName\", inplace=True)\n",
    "merged_indicators_data_df.drop(columns=\"Value\", inplace=True)\n",
    "\n",
    "counter = 1\n",
    "for indicator_name_df in indicator_code_df_name_list:\n",
    "    indicator_name_df.rename(columns={k: v for k, v in rename_map.items() if k in indicator_name_df.columns}, inplace=True)\n",
    "    indicator_name_df.dropna(subset=[\"CountryCode\", \"Year\", \"Value\"], inplace=True)\n",
    "    indicator_name_df[\"Year\"]  = pd.to_numeric(indicator_name_df[\"Year\"], errors=\"coerce\")\n",
    "    indicator_name_df[\"NumericValue\"] = pd.to_numeric(indicator_name_df[\"NumericValue\"], errors=\"coerce\")\n",
    "    if not indicator_name_df.empty:\n",
    "        new_name = indicator_name_df[\"IndicatorCode\"].iloc[0]  # get value from the row\n",
    "        if indicator_name_df[\"NumericValue\"].isna().all(): \n",
    "            indicator_name_df.rename(columns={\"Value\": new_name}, inplace=True)\n",
    "            indicator_name_df.drop(columns=\"NumericValue\", inplace=True)\n",
    "        else:\n",
    "            indicator_name_df.rename(columns={\"NumericValue\": new_name}, inplace=True) \n",
    "            indicator_name_df.drop(columns=\"Value\", inplace=True)  \n",
    "        \n",
    "        indicator_name_df.drop(columns=\"IndicatorCode\", inplace=True)\n",
    "        indicator_name_df.drop(columns=\"IndicatorName\", inplace=True)  \n",
    "\n",
    "    merged_indicators_data_df = pd.merge(merged_indicators_data_df, indicator_name_df, on=[\"CountryCode\", \"Year\"], how=\"left\") \n",
    "    counter += 1\n",
    "\n",
    "merged_indicators_data_df.drop(columns=[\"IndicatorCode\",\"IndicatorName\",\"NumericValue\",\"Value\"], inplace=True)   \n",
    "\n",
    "merged_indicators_data_df.to_csv(\"../data/merged_indicators_data_df.csv\")\n",
    "\n",
    "print(merged_indicators_data_df.head(2))\n",
    "\n",
    "\n",
    "predictors = merged_indicators_data_df.columns[3:]\n",
    "numerical_predictors = (merged_indicators_data_df[predictors].select_dtypes(include=['number']).columns.to_list())\n",
    "corr_matrix = merged_indicators_data_df[numerical_predictors + [target_indicator]].corr()\n",
    "    \n",
    "plt.figure( figsize=(10, 5))\n",
    "sns.heatmap(corr_matrix, vmax=1, vmin=-1, square=True, annot=True, cmap=\"viridis\")\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
